{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to the root directory of the project\n",
    "import os\n",
    "if os.getcwd().split(\"/\")[-1] == \"examples\":\n",
    "    os.chdir('..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to run this notebook on Google Colab, we first have to install `ScanDy` and download (an example version of) the dataset and the results from the evolutionary parameter optimization for all models from Google drive. The following code cell will prepare all of this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the ScanDy framework via pip\n",
    "!pip install scandy\n",
    "\n",
    "# download the VidCom_example dataset from google drive using gdown\n",
    "!pip install gdown\n",
    "# dataset is stored at https://drive.google.com/file/d/14kJDD_5ECP2vhgonhn5iQ5qnREDIqTTr/view?usp=sharing \n",
    "file_id = '14kJDD_5ECP2vhgonhn5iQ5qnREDIqTTr'\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "output = 'vidcom_example.zip'\n",
    "!gdown $url -O $output\n",
    "!unzip $output\n",
    "\n",
    "# Manuscript evolution results are stored at https://drive.google.com/file/d/1nVPwJEdJOAE-lbQhRteIai1g5YKmIgdJ/view?usp=sharing \n",
    "file_id = '1nVPwJEdJOAE-lbQhRteIai1g5YKmIgdJ'\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "output = 'manuscript_results.zip'\n",
    "!gdown $url -O $output\n",
    "!unzip $output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = '1nVPwJEdJOAE-lbQhRteIai1g5YKmIgdJ'\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "output = 'manuscript_results.zip'\n",
    "!gdown $url -O $output\n",
    "!unzip $output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib.colors import to_rgb\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "\n",
    "from scandy.models.LocationModel import LocationModel\n",
    "from scandy.models.ObjectModel import ObjectModel\n",
    "from scandy.utils.dataclass import Dataset\n",
    "import scandy.utils.functions as uf\n",
    "\n",
    "from neurolib.utils.parameterSpace import ParameterSpace\n",
    "from neurolib.optimize.evolution import Evolution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset with the randomly generated train-test split used in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidlist = ['field03', 'dance01', 'dance02', 'foutain02', 'garden04', 'garden06', 'garden07', 'garden09', 'park01', 'park06', 'park09', 'road02', 'road04', 'road05', 'robarm01', 'room01', 'room02', 'room03', 'tommy02', 'uscdog01', 'walkway01', 'walkway02', 'walkway03']\n",
    "random.seed(12345)\n",
    "trainlist = sorted(random.sample(sorted(vidlist), 10))\n",
    "testlist = sorted([vidname for vidname in vidlist if vidname not in trainlist])\n",
    "print(\"trainlist = \", trainlist, \"\\ntestlist =\", testlist)\n",
    "\n",
    "datadict = {\n",
    "    \"PATH\": \"VidCom_example/\",  # previously downloaded & extracted dataset  \n",
    "    'FPS' : 30,\n",
    "    'PX_TO_DVA' : 0.06,\n",
    "    'FRAMES_ALL_VIDS' : 300,\n",
    "    'gt_foveation_df' : '2021-12-04_VidCom_GT_fov_df',\n",
    "    # hacky way of initializing, necessary since VidCom_example only has 1 video\n",
    "    'used_videos' : vidlist,\n",
    "    'trainset' : trainlist,\n",
    "    'testset' : testlist,\n",
    "}\n",
    "VidCom = Dataset(datadict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the ground truth human data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_amp_dva = VidCom.gt_foveation_df[\"sac_amp_dva\"].dropna().values\n",
    "gt_dur_ms = VidCom.gt_foveation_df[\"duration_ms\"].dropna().values\n",
    "\n",
    "gt_amp_dva_train = VidCom.train_foveation_df[\"sac_amp_dva\"].dropna().values\n",
    "gt_dur_ms_train = VidCom.train_foveation_df[\"duration_ms\"].dropna().values\n",
    "\n",
    "gt_amp_dva_test = VidCom.test_foveation_df[\"sac_amp_dva\"].dropna().values\n",
    "gt_dur_ms_test = VidCom.test_foveation_df[\"duration_ms\"].dropna().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit distributions to the histograms and scale them appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ampfit = stats.expon.fit(gt_amp_dva)\n",
    "ampX = np.linspace(0,50, 200)\n",
    "ampPDF = stats.expon.pdf(ampX, *ampfit)\n",
    "\n",
    "durfit = stats.norm.fit(np.log10(gt_dur_ms))\n",
    "durX = np.linspace(1,4, 200)\n",
    "durPDF = stats.norm.pdf(durX, *durfit)\n",
    "print(durfit, ampfit)\n",
    "\n",
    "c_count, b_count = np.histogram(np.log10(gt_dur_ms), density=False,bins=40)\n",
    "c_dense, b_dense = np.histogram(np.log10(gt_dur_ms), density=True,bins=40)\n",
    "FD_fac = c_count.max()/c_dense.max()\n",
    "c_count, b_count = np.histogram(gt_amp_dva, density=False,bins=60)\n",
    "c_dense, b_dense = np.histogram(gt_amp_dva, density=True,bins=60)\n",
    "SA_fac = c_count.max()/c_dense.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"report with basis e: \", stats.norm.fit(np.log(gt_dur_ms)))\n",
    "print(\"expected value is \", np.exp(5.734790631554358 + 0.5 * 0.8380120606761086**2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 4\n",
    "### a & b\n",
    "Ground truth scanpath statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use different color palatte from the functional evaluation (see below)\n",
    "cl = sns.color_palette(\"Dark2\")\n",
    "\n",
    "fig, axs = plt.subplots(1,2,dpi=150, figsize=(8,3), sharey=True)\n",
    "sns.histplot(data=np.log10(gt_dur_ms), kde=False, ax=axs[0], bins=40, color=cl[0])\n",
    "axs[0].plot(durX, durPDF*FD_fac, color='k', ls=':')\n",
    "axs[0].set_xticks([1,2,3,4])\n",
    "axs[0].set_xticklabels([10,100,1000,10000])\n",
    "axs[0].set_xlabel('Foveation duration [ms]', size=14)\n",
    "axs[0].set_ylabel('Count', size=14)\n",
    "sns.histplot(data=gt_amp_dva, kde=False, ax=axs[1], bins=60, color=cl[0])\n",
    "axs[1].set_xlabel('Saccade amplitude [dva]', size=14)\n",
    "axs[1].set_xlim([0, 50])\n",
    "axs[1].plot(ampX, ampPDF*SA_fac, color='k', ls=':', label='Fit')\n",
    "axs[0].tick_params(labelsize=12)\n",
    "axs[1].tick_params(labelsize=12)\n",
    "sns.despine()\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c & d\n",
    "Compare the CDF summary statistics of the human data with the models. Show training in transparent and test in opaque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = sns.color_palette(\"Dark2\")\n",
    "\n",
    "names = [ 'L.ll', 'L.hl', 'O.ll', 'O.cb']\n",
    "gtname = 'Human data'\n",
    "run_ids = [\n",
    "    'loc_train_molin_64-32-50_2023-03-09-01H-04M-33S_22332349',\n",
    "    'loc_train_TASEDnet_64-32-50_2023-03-09-01H-02M-20S_22332348',\n",
    "    'obj_train_molin_64-32-50_2023-03-09-01H-04M-58S_22332350',\n",
    "    'obj_train_None_64-32-50_2023-03-09-01H-05M-43S_22332351',\n",
    "]\n",
    "# prepare custom legend\n",
    "handles1 = []; handles2 = []\n",
    "for ind in [0,1,2,3,5]:\n",
    "    rgb = to_rgb(cl[ind])\n",
    "    handles1.append(plt.Rectangle((0, 0), 0, 0, facecolor=rgb, edgecolor=rgb))\n",
    "    rgb = 0.5 + 0.5 * np.array(rgb)  # make whiter\n",
    "    handles2.append(plt.Rectangle((0, 0), 0, 0, facecolor=rgb, edgecolor=rgb))\n",
    "\n",
    "fig, axs = plt.subplots(1,2,dpi=150, figsize=(8,3), sharey=True)\n",
    "for modus in [\"train\", \"test\"]:\n",
    "    c_idx = 0\n",
    "    print(modus)\n",
    "\n",
    "    if modus == \"train\":\n",
    "        videoset = VidCom.trainset\n",
    "        gt_amp_dva = VidCom.train_foveation_df[\"sac_amp_dva\"].dropna().values\n",
    "        gt_dur_ms = VidCom.train_foveation_df[\"duration_ms\"].dropna().values\n",
    "        kwargs = {\"lw\":3, \"alpha\":0.3} #\"ls\":\"dotted\", \n",
    "    else:\n",
    "        videoset = VidCom.testset\n",
    "        gt_amp_dva = VidCom.test_foveation_df[\"sac_amp_dva\"].dropna().values\n",
    "        gt_dur_ms = VidCom.test_foveation_df[\"duration_ms\"].dropna().values\n",
    "        kwargs = {\"lw\":2}#, \"ls\":\"dotted\", \"alpha\":0.5}\n",
    "\n",
    "    df_res_pxMolin_top0 = pd.read_csv(f'./ScanDy_results/{run_ids[0]}/{modus}res_df_top0.csv')\n",
    "    # df_res_pxMolin_top0 = df_res_pxMolin_top0[df_res_pxMolin_top0['video'].isin(videoset)]\n",
    "    px_llf_dur_ms = df_res_pxMolin_top0[\"duration_ms\"].dropna().values\n",
    "    px_llf_amp_dva = df_res_pxMolin_top0[\"sac_amp_dva\"].dropna().values\n",
    "\n",
    "    df_res_pxTased_top0 = pd.read_csv(f'./ScanDy_results/{run_ids[1]}/{modus}res_df_top0.csv')\n",
    "    # df_res_pxTased_top0 = df_res_pxTased_top0[df_res_pxTased_top0['video'].isin(videoset)]\n",
    "    px_hlf_dur_ms = df_res_pxTased_top0[\"duration_ms\"].dropna().values \n",
    "    px_hlf_amp_dva = df_res_pxTased_top0[\"sac_amp_dva\"].dropna().values \n",
    "\n",
    "    df_res_objMolin_top0 = pd.read_csv(f'./ScanDy_results/{run_ids[2]}/{modus}res_df_top0.csv')\n",
    "    # df_res_objMolin_top0 = df_res_objMolin_top0[df_res_objMolin_top0['video'].isin(videoset)]\n",
    "    obj_llf_dur_ms = df_res_objMolin_top0[\"duration_ms\"].dropna().values\n",
    "    obj_llf_amp_dva = df_res_objMolin_top0[\"sac_amp_dva\"].dropna().values\n",
    "\n",
    "    df_res_objNone_top0 = pd.read_csv(f'./ScanDy_results/{run_ids[3]}/{modus}res_df_top0.csv')\n",
    "    # df_res_objNone_top0 = df_res_objNone_top0[df_res_objNone_top0['video'].isin(videoset)]\n",
    "    obj_cb_dur_ms = df_res_objNone_top0[\"duration_ms\"].dropna().values\n",
    "    obj_cb_amp_dva = df_res_objNone_top0[\"sac_amp_dva\"].dropna().values\n",
    "\n",
    "    nbins = 60\n",
    "    axs[0].hist(np.log10(px_llf_dur_ms), nbins, density=True, histtype='step', cumulative=True, label=names[0], color=cl[1], **kwargs)\n",
    "    axs[0].hist(np.log10(px_hlf_dur_ms), nbins, density=True, histtype='step', cumulative=True, label=names[1], color=cl[2], **kwargs)\n",
    "    axs[0].hist(np.log10(obj_llf_dur_ms), nbins, density=True, histtype='step', cumulative=True, label=names[2], color=cl[3], **kwargs)\n",
    "    axs[0].hist(np.log10(obj_cb_dur_ms), nbins, density=True, histtype='step', cumulative=True, label=names[3], color=cl[5], **kwargs)\n",
    "    axs[0].hist(np.log10(gt_dur_ms), nbins, density=True, histtype='step', cumulative=True, label=gtname, color=cl[0], **kwargs)\n",
    "    axs[0].set_xticks([1,2,3,4])\n",
    "    axs[0].set_xticklabels([10,100,1000,10000], size=14)\n",
    "    axs[0].tick_params(labelsize=12)\n",
    "    axs[0].set_xlabel('Foveation duration [ms]', size=14)\n",
    "    axs[0].set_ylabel('CDF', size=14)\n",
    "    axs[1].hist(px_llf_amp_dva, nbins, density=True, histtype='step', cumulative=True, label=names[0], color=cl[1], **kwargs)\n",
    "    axs[1].hist(px_hlf_amp_dva, nbins, density=True, histtype='step', cumulative=True, label=names[1], color=cl[2], **kwargs)\n",
    "    axs[1].hist(obj_llf_amp_dva, nbins, density=True, histtype='step', cumulative=True, label=names[2], color=cl[3], **kwargs)\n",
    "    axs[1].hist(obj_cb_amp_dva, nbins, density=True, histtype='step', cumulative=True, label=names[3], color=cl[5], **kwargs)\n",
    "    axs[1].hist(gt_amp_dva, nbins, density=True, histtype='step', cumulative=True, label=gtname, color=cl[0], **kwargs)\n",
    "    axs[1].set_xlabel('Saccade amplitude [dva]', size=14)\n",
    "    axs[1].tick_params(labelsize=12)\n",
    "    axs[1].set_xlim([0, 50])\n",
    "    #axs[1].legend(loc='lower right')\n",
    "    uf.fix_hist_step_vertical_line_at_end(axs[0])\n",
    "    uf.fix_hist_step_vertical_line_at_end(axs[1])\n",
    "axs[1].legend(bbox_to_anchor=(1,0), loc='lower right', \n",
    "            frameon=False, handles=[tuple(handles1), tuple(handles2)], labels=[\"Test set\", \"Training set\"],\n",
    "            title=\"\", handlelength=3, handler_map={tuple: HandlerTuple(ndivide=None, pad=0)}, fontsize=11)\n",
    "\n",
    "sns.despine(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(px_hlf_dur_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create legend separately\n",
    "fig, ax = plt.subplots(1,1,dpi=150, figsize=(4,3))\n",
    "ax.plot([0,1], [0,0], lw=2, label=gtname, color=cl[0])\n",
    "ax.plot([0,1], [0,0], lw=2, label=\"L.ll model\", color=cl[1])#names[0])\n",
    "ax.plot([0,1], [0,0], lw=2, label=\"L.hl model\", color=cl[2])#names[1])\n",
    "ax.plot([0,1], [0,0], lw=2, label=\"O.ll model\", color=cl[3])#names[2])\n",
    "ax.plot([0,1], [9,9], lw=2, label=\"O.cb model\", color=cl[5])#names[3])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 5\n",
    "\n",
    "### a) Foveation categories over time for human data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = sns.color_palette()\n",
    "\n",
    "BDIR_per_frames_train = np.zeros((4,300))\n",
    "BDIR_per_frames = np.zeros((4,300))\n",
    "bdir_to_row = {'B': 0, 'D': 1, 'I': 2, 'R': 3}\n",
    "for index, row in VidCom.train_foveation_df.iterrows():\n",
    "    BDIR_per_frames_train[bdir_to_row[row['fov_category']], row['frame_start']:row['frame_end']+1] += 1\n",
    "for index, row in VidCom.test_foveation_df.iterrows():\n",
    "    BDIR_per_frames[bdir_to_row[row['fov_category']], row['frame_start']:row['frame_end']+1] += 1\n",
    "\n",
    "combined_per_frames_train = np.sum(BDIR_per_frames_train, axis=0)\n",
    "combined_per_frames = np.sum(BDIR_per_frames, axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(dpi=200, figsize=(4,2.5))\n",
    "ax.plot(BDIR_per_frames_train[0] / combined_per_frames_train * 100, color=cl[0], lw=2, ls='-', alpha=0.25)\n",
    "ax.plot(BDIR_per_frames_train[1] / combined_per_frames_train * 100, color=cl[1], lw=2, ls='-', alpha=0.25)\n",
    "ax.plot(BDIR_per_frames_train[2] / combined_per_frames_train * 100, color=cl[2], lw=2, ls='-', alpha=0.25)\n",
    "ax.plot(BDIR_per_frames_train[3] / combined_per_frames_train * 100, color=cl[3], lw=2, ls='-', alpha=0.25)\n",
    "ax.plot(BDIR_per_frames[0] / combined_per_frames * 100, color=cl[0], label='Background')\n",
    "ax.plot(BDIR_per_frames[1] / combined_per_frames * 100, color=cl[1], label='Detection')\n",
    "ax.plot(BDIR_per_frames[2] / combined_per_frames * 100, color=cl[2], label='Inspection')\n",
    "ax.plot(BDIR_per_frames[3] / combined_per_frames * 100, color=cl[3], label='Revisit')\n",
    "ax.set(xlabel='Time [frames]', ylabel='Percentage') # title='Ground truth foveation category over time', \n",
    "# plt.legend(); \n",
    "sns.despine(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the supplement, check the temporally resolved ratios for all models! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_idx in range(4):\n",
    "    runid = run_ids[model_idx]\n",
    "    name = names[model_idx]\n",
    "    \n",
    "    if 'obj_' in runid:\n",
    "        model = ObjectModel(VidCom)\n",
    "        parameters = ['ddm_thres', 'ddm_sig', 'att_dva', 'ior_decay', 'ior_inobj']\n",
    "    elif 'loc_' in runid:\n",
    "        model = LocationModel(VidCom)\n",
    "        parameters = ['ddm_thres', 'ddm_sig', 'att_dva', 'ior_decay', 'ior_dva']\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only Object- and Location-based are implemented\")\n",
    "\n",
    "    train_df = pd.read_csv(f'ScanDy_results/{runid}/trainres_df_top{0}.csv')\n",
    "    test_df = pd.read_csv(f'ScanDy_results/{runid}/testres_df_top{0}.csv')\n",
    "    model.result_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "    ratios = model.functional_event_courses(videos_to_eval=\"test\")\n",
    "    ratios_train = model.functional_event_courses(videos_to_eval=\"train\")\n",
    "\n",
    "    print(name)\n",
    "    fig, ax = plt.subplots(dpi=200, figsize=(4,2.5))\n",
    "    ax.plot(ratios_train[0], color=cl[0], lw=2, ls='-', alpha=0.25)\n",
    "    ax.plot(ratios_train[1], color=cl[1], lw=2, ls='-', alpha=0.25)\n",
    "    ax.plot(ratios_train[2], color=cl[2], lw=2, ls='-', alpha=0.25)\n",
    "    ax.plot(ratios_train[3], color=cl[3], lw=2, ls='-', alpha=0.25)\n",
    "    ax.plot(ratios[0], color=cl[0], label='Background')\n",
    "    ax.plot(ratios[1], color=cl[1], label='Detection')\n",
    "    ax.plot(ratios[2], color=cl[2], label='Inspection')\n",
    "    ax.plot(ratios[3], color=cl[3], label='Revisit')\n",
    "    # ax.set(title=name, xlabel='Time [frames]', ylabel='Percentage', ylim=[0,100]) # title='Ground truth foveation category over time', \n",
    "    ax.set(xlabel='Time [frames]', ylabel='Percentage', ylim=[0,100]) # title='Ground truth foveation category over time', \n",
    "    sns.despine(); plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In main paper, reduce this to the barplot of the mean ratios, which is calculated afterwards.\n",
    "First, look into the train/test boxplots!\n",
    "\n",
    "## Fig 6: BDIR fractions relative to the human data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fraction of the stimulus time taken up by foveation events in the human data: \", VidCom.get_foveation_ratio())\n",
    "print(\"This is 100% for the models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,4, sharex=True, sharey=True, figsize=(8,3), dpi=200)\n",
    "report_par_decimals = [3,3,2,1,2]\n",
    "\n",
    "subjects_fovcat_train = list(VidCom.get_fovcat_ratio(\"train\").values())\n",
    "subjects_fovcat_test = list(VidCom.get_fovcat_ratio(\"test\").values())\n",
    "\n",
    "mean_fovcats_train = []\n",
    "mean_fovcats_test = []\n",
    "\n",
    "evol = Evolution(lambda x: x, ParameterSpace(['mock'], [[0, 1]]))\n",
    "for ax_i, ax in enumerate(axes.flat):\n",
    "    runid = run_ids[ax_i]\n",
    "    print(runid)\n",
    "    DILLNAME = f'{runid}.dill'\n",
    "    if 'obj_' in runid:\n",
    "        model = ObjectModel(VidCom)\n",
    "        parameters = ['ddm_thres', 'ddm_sig', 'att_dva', 'ior_decay', 'ior_inobj']\n",
    "    elif 'loc_' in runid:\n",
    "        model = LocationModel(VidCom)\n",
    "        parameters = ['ddm_thres', 'ddm_sig', 'att_dva', 'ior_decay', 'ior_dva']\n",
    "    evol = evol.loadEvolution(f'ScanDy_results/{runid}/{DILLNAME}')\n",
    "    df_evol = evol.dfEvolution(outputs=True).copy()\n",
    "    df_top32 = df_evol.sort_values('score', ascending=False)[:32]\n",
    "    # read in test simulation results\n",
    "    test_fovcats = []\n",
    "    for i in range(32):\n",
    "        model.result_df = pd.read_csv(f'ScanDy_results/{runid}/testres_df_top{i}.csv')\n",
    "        test_fovcats.append(np.array(list(model.get_fovcat_ratio().values())) )\n",
    "    df_top32['test_fov_cat'] = test_fovcats\n",
    "\n",
    "    print(runid, \"mean params\")\n",
    "    for i, par in enumerate(parameters):\n",
    "        top_par = round(df_top32[par].iloc[0],report_par_decimals[i])\n",
    "        print(f'{par} = ${round(df_top32[par].mean(),report_par_decimals[i])} \\pm {round(df_top32[par].std(),report_par_decimals[i])}$     & {top_par}' )\n",
    "    print(\"Balancing of fitness function\")\n",
    "    print(\"$d_{FD} =\", f'{round(df_top32[\"f0\"].mean(), 3)} \\pm {round(df_top32[\"f0\"].std(), 3)}$   top0: {round(df_top32[\"f0\"].iloc[0], 3)}' )\n",
    "    print(\"$d_{SA} =\", f'{round(df_top32[\"f1\"].mean(), 3)} \\pm {round(df_top32[\"f1\"].std(), 3)}$   top0: {round(df_top32[\"f1\"].iloc[0], 3)}' )\n",
    "\n",
    "\n",
    "    fovcats_train = [df_top32['fov_cat'].iloc[indv] for indv in range(32)]\n",
    "    mean_fovcats_train.append(np.mean(np.array(fovcats_train), axis=0))\n",
    "    print(\"Train, \", names[ax_i], np.mean(np.array(fovcats_train), axis=0))\n",
    "    train_rel_fovcat = [df_top32['fov_cat'].iloc[indv] / np.array(subjects_fovcat_train) for indv in range(32)]\n",
    "    \n",
    "    fovcats_test = [df_top32['test_fov_cat'].iloc[indv] for indv in range(32)]\n",
    "    mean_fovcats_test.append(np.mean(np.array(fovcats_test), axis=0))\n",
    "    print(\"Test, \", names[ax_i], np.mean(np.array(fovcats_test), axis=0))\n",
    "    print(\"Test ratio to GT, \", names[ax_i], np.mean(np.array(fovcats_test), axis=0) / np.array(subjects_fovcat_test))\n",
    "    test_rel_fovcat = [df_top32['test_fov_cat'].iloc[indv] / np.array(subjects_fovcat_test) for indv in range(32)]\n",
    "    df_train_fovcats_rel_gt = pd.DataFrame(index=[f'Indv. Top {t}' for t in range(32)] , \n",
    "                                     columns=['B', 'D', 'I', 'R'], data=train_rel_fovcat\n",
    "                                     ).assign(Data='training set')\n",
    "    df_test_fovcats_rel_gt = pd.DataFrame(index=[f'Indv. Top {t}' for t in range(32)] , \n",
    "                                          columns=['B', 'D', 'I', 'R'], data=test_rel_fovcat\n",
    "                                          ).assign(Data='test set')\n",
    "    cdf = pd.concat([df_test_fovcats_rel_gt, df_train_fovcats_rel_gt])\n",
    "    mdf = pd.melt(cdf, id_vars=['Data'], var_name=['Foveation category'])\n",
    "\n",
    "    sns.violinplot(x=\"Foveation category\", y=\"value\", hue=\"Data\", data=mdf, ax=ax, split=True, linewidth=1, palette={\"test set\": cl[0], \"training set\": \".85\"})    \n",
    "    # df_fovcats_rel_gt.boxplot(ax=ax, grid=False)\n",
    "    handles = []\n",
    "    for ind, violin in enumerate(ax.findobj(PolyCollection)):\n",
    "        rgb = to_rgb(cl[ind // 2])\n",
    "        if ind % 2 != 0:\n",
    "            rgb = 0.5 + 0.5 * np.array(rgb)  # make whiter\n",
    "        violin.set_facecolor(rgb)\n",
    "        handles.append(plt.Rectangle((0, 0), 0, 0, facecolor=rgb, edgecolor=rgb))\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_yticks([0.25,0.5,1,1.5,2])\n",
    "    ax.set_yticklabels([0.25,0.5,1,1.5,2])\n",
    "    ax.axhline(1, color='k', ls=':')\n",
    "\n",
    "    if (ax_i%4)==0:\n",
    "        ax.set_ylabel('Fraction of viewing time\\nrelative to human data', size=12)\n",
    "        # ax.set_xlabel('Fov. category', size=14)\n",
    "    else:\n",
    "        ax.set_ylabel('')\n",
    "    if ax_i==3:\n",
    "        ax.legend(bbox_to_anchor=(1,0), loc='lower right', \n",
    "                  frameon=False, handles=[tuple(handles[::2]), tuple(handles[1::2])], labels=[\"Test set\", \"Training set\"],\n",
    "                  title=\"\", handlelength=3, handler_map={tuple: HandlerTuple(ndivide=None, pad=0)}, fontsize=9)\n",
    "    else:\n",
    "        ax.get_legend().remove()\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_title(names[ax_i])\n",
    "fig.text(0.55, 0.0, 'Foveation category', size=12, ha='center')    \n",
    "plt.tight_layout()\n",
    "sns.despine(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_fovcat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_fovcat_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 5b Barplots\n",
    "Use the means from the distributions plotted in Fig 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names_r = names[::-1]\n",
    "names_r = [\"O.cb model\", \"O.ll model\", \"L.hl model\", \"L.ll model\"]\n",
    "mean_fovcats_train_r = mean_fovcats_train[::-1]\n",
    "mean_fovcats_test_r = mean_fovcats_test[::-1]\n",
    "\n",
    "subjects_fovcat_train = list(VidCom.get_fovcat_ratio(\"train\").values())\n",
    "subjects_fovcat_train = list(VidCom.get_fovcat_ratio(\"train\").values())\n",
    "\n",
    "df_fovcats_train = pd.DataFrame(index=names_r + ['Human\\ndata'], \n",
    "                        columns=['B', 'D*', 'I', 'R'],\n",
    "                        data= mean_fovcats_train_r + [subjects_fovcat_train/sum(subjects_fovcat_train)])\n",
    "df_fovcats_test = pd.DataFrame(index=names_r + ['Human\\ndata'], \n",
    "                        columns=['B', 'D*', 'I', 'R'],\n",
    "                        data= mean_fovcats_test_r + [subjects_fovcat_test/sum(subjects_fovcat_test)])\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(3.5,2.5),dpi=150)\n",
    "fig, ax = plt.subplots(figsize=(3.7,2.5),dpi=150)\n",
    "df_fovcats_train.plot.barh(stacked=True, ax=ax,rot=0, legend=False)#.legend(bbox_to_anchor=(0.3, 1.5))\n",
    "ax.set_frame_on(False); ax.set(xlabel = 'Ratio of events')#, title = 'Trainset')\n",
    "print(\"Trainset\")\n",
    "plt.tight_layout(); plt.show()\n",
    "fig, ax = plt.subplots(figsize=(3.7,2.5),dpi=150)\n",
    "df_fovcats_test.plot.barh(stacked=True, ax=ax,rot=0, legend=False)#.legend(bbox_to_anchor=(0.3, 1.5))\n",
    "ax.set_frame_on(False); ax.set(xlabel = 'Ratio of events')#, title = 'Testset')\n",
    "print(\"Testset\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplemental material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = sorted(VidCom.gt_foveation_df.video.unique())\n",
    "\n",
    "# go through all videos and print a list that says for each if it is in the training or test set \n",
    "print(f\"Name\\t \\t#Subjects\\t \\tTrain/test set\")\n",
    "for video in videos:\n",
    "    nsubj = len(VidCom.gt_foveation_df[VidCom.gt_foveation_df.video==video].subject.unique())\n",
    "    if video in VidCom.trainset:\n",
    "        print(f\"{video}\\t \\t{nsubj}\\t \\ttrain\")\n",
    "    else:\n",
    "        print(f\"{video}\\t \\t{nsubj}\\t \\ttest\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1 & S2 are about parameter understanding and robustness for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where to get parameters from? --> previous evolution!\n",
    "runid = 'loc_train_molin_64-32-50_2023-03-09-01H-04M-33S_22332349'\n",
    "model = LocationModel(VidCom)\n",
    "parameters = ['ddm_thres', 'ddm_sig', 'att_dva', 'ior_decay', 'ior_dva']\n",
    "par_sym = [r'DDM thres. $\\theta$', r'DDM noise $s$', r'Sensitivity spread $\\sigma_S$', r'IOR slope $1/r$', r'IOR spread $\\sigma_I$']\n",
    "relative_par_vals = [0.5, 0.75, 0.9, 1.1, 1.25, 2]\n",
    "\n",
    "uf.plot_var_pars(model, 'ScanDy_results/', runid, parameters, par_sym, relative_par_vals)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same for object based model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where to get parameters from? --> previous evolution!\n",
    "runid = 'obj_train_molin_64-32-50_2023-03-09-01H-04M-58S_22332350'\n",
    "model = ObjectModel(VidCom)\n",
    "parameters = ['ddm_thres', 'ddm_sig', 'att_dva', 'ior_decay', 'ior_inobj']\n",
    "par_sym = [r'DDM thres. $\\theta$', r'DDM noise $s$', r'Sensitivity spread $\\sigma_S$', r'IOR slope $1/r$', r'Object IOR $\\xi$']\n",
    "relative_par_vals = [0.5, 0.75, 0.9, 1.1, 1.25, 2]\n",
    "\n",
    "uf.plot_var_pars(model, runid, parameters, par_sym, relative_par_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3-6: Parameter spaces of the 4 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = [\n",
    "    'loc_train_molin_64-32-50_2023-03-09-01H-04M-33S_22332349',\n",
    "    'loc_train_TASEDnet_64-32-50_2023-03-09-01H-02M-20S_22332348',\n",
    "    'obj_train_molin_64-32-50_2023-03-09-01H-04M-58S_22332350',\n",
    "    'obj_train_None_64-32-50_2023-03-09-01H-05M-43S_22332351',\n",
    "]\n",
    "for runid in run_ids:\n",
    "    DILLNAME = f'{runid}.dill'\n",
    "    evol = Evolution(lambda x: x, ParameterSpace(['mock'], [[0, 1]]))\n",
    "    evol = evol.loadEvolution(f'ScanDy_results/{runid}/{DILLNAME}')\n",
    "    evol.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S7 see above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a7dae82b130ec9d80cfefc4262e34c3661939d310e111163fc3ded324ad374c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
